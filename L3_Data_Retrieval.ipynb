{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68dc8000",
   "metadata": {},
   "source": [
    "# Data Retrieval and Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79dfa3b",
   "metadata": {},
   "source": [
    "## Speeding Up Data Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dfb140",
   "metadata": {},
   "source": [
    "- We will go through the things we can do to speed data retrieval with Polars and Pandas.\n",
    "- This will also provide an intuition for what database management systems automatically do during data retrival."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750c03c0",
   "metadata": {},
   "source": [
    "### Choose Columns When Loading Data\n",
    "- Instead of loading all data: df = pd.read_csv(DATA_PATH)\n",
    "- We can only load the data with the columns we will work with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8f80ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "DATA_PATH = \"data_path\"\n",
    "\n",
    "# load data with selected columns using pandas\n",
    "df = pd.read_csv(DATA_PATH, usecols=['column1', 'column2', 'column5'])\n",
    "\n",
    "# we can also only load limited number of rows when exploring\n",
    "df = pd.read_csv(DATA_PATH, nrows=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4702d43d",
   "metadata": {},
   "source": [
    "### Choose Right Data Type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0321bf",
   "metadata": {},
   "source": [
    "Python has the following built-in data types:\n",
    "- Text type: str\n",
    "- Numeric types: int, float, complex\n",
    "- Sequence types: list, tuple, range\n",
    "- Mapping type: dict\n",
    "- Set types: set, frozenset\n",
    "- Boolean type: bool\n",
    "- Binary types: bytes, bytearray, memoryview\n",
    "- None type: NoneType"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49e396b",
   "metadata": {},
   "source": [
    "We care about data types since:\n",
    "- Data types define what operations can be performed.\n",
    "- Storing columns as certain data types can reduce memory requirements for loading a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833e5fd0",
   "metadata": {},
   "source": [
    "Below is an example of how we can set data type for columns of a pd dataframe when loading, to improve memory usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5e1f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype_dict = {'column1': 'int16', 'column2': 'int32'}\n",
    "df = pd.read_csv('file.csv', dtype=dtype_dict)\n",
    "\n",
    "# Comparision:\n",
    "\n",
    "## Memory Size:\n",
    "### np.int16: Uses 16 bits (2 bytes) to store an integer.\n",
    "### np.int32: Uses 32 bits (4 bytes) to store an integer.\n",
    "\n",
    "## Range of Values:\n",
    "### np.int16: integers from -32,768 to 32,767.\n",
    "### np.int32: integers from -2,147,483,648 to 2,147,483,647\n",
    "\n",
    "## Use Cases:\n",
    "### Use np.int16 when you need to save memory and your integers fall within the smaller range."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4529ae7",
   "metadata": {},
   "source": [
    "### Adjust Data Wrangling Order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7d7caf",
   "metadata": {},
   "source": [
    "Consider the below example, the original data wrangling pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290fbc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('path').groupby('city').agg(n_adresses=('adress', 'nunique'),n_people=('name', 'size')).loc[lambda d: d['city'] == 'Amsterdam']\n",
    "# first groug by city\n",
    "# then compute aggregated measure\n",
    "# find the aggregated measure corresponding to city Amsterdam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b4c3bd",
   "metadata": {},
   "source": [
    "We can instead execute the imporved pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e82509",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('path', usecols=['city', 'adress', 'name']).loc[lambda d: d['city'] == 'Amsterdam'].groupby('city').agg(n_adresses=('adress', 'nunique'), n_people=('name', 'size'))\n",
    "# only load columns we use\n",
    "# first filter the data to find observation with city name Amsterdam\n",
    "# then group by city and compute aggrgetaed measure\n",
    "# in this case, we only compute aggregated measures for Amsterdam, which save time and computation resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675d4980",
   "metadata": {},
   "source": [
    "The advantage of Polars over Pandas is that the Polars library can optimize the original data pipeline itself, without manual adjustment like we conducted for Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65b847a",
   "metadata": {},
   "source": [
    "### Use Polars Library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58636267",
   "metadata": {},
   "source": [
    "Polars can outperform Pandas because it allows two types of evaluation (execution of code):\n",
    "* **Eager Evaluation:**\n",
    "    * Operations are executed immediately\n",
    "    * Results are computed and stored in memory right away\n",
    "    * e.g. pd.read_csv(\"example.csv\") or pl.read_csv(\"example.csv\")\n",
    "* **Lazy Evaluation:**\n",
    "    * Operations are deferred until explicitly executed\n",
    "    * Query plan is built first, then optimised before execution\n",
    "    * Better for large datasets and complex operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e98a5c",
   "metadata": {},
   "source": [
    "Example of lazy evaluation in polars:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e593e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lazy_frame = pl.scan_csv(\"example.csv\").select(\"col_1\") # create query\n",
    "eager_frame = lazy_frame.collect() # polars inspect the query, optimize it, and then execute the query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955dec55",
   "metadata": {},
   "source": [
    "How polars optimises the query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09bb46d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"775pt\" height=\"164pt\" viewBox=\"0.00 0.00 775.00 164.00\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 159.5)\">\n",
       "<title>polars_query</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-159.5 770.75,-159.5 770.75,4 -4,4\"/>\n",
       "<!-- p2 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>p2</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"531.62,-59.75 235.12,-59.75 235.12,0 531.62,0 531.62,-59.75\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"383.38\" y=\"-42.45\" font-family=\"Monospace\" font-size=\"14.00\">Csv SCAN [./example.csv]</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"383.38\" y=\"-25.2\" font-family=\"Monospace\" font-size=\"14.00\">π 3/7;</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"383.38\" y=\"-7.95\" font-family=\"Monospace\" font-size=\"14.00\">σ [(col(&quot;city&quot;)) == (&quot;Amsterdam&quot;)]</text>\n",
       "</g>\n",
       "<!-- p1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>p1</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"766.75,-155.5 0,-155.5 0,-95.75 766.75,-95.75 766.75,-155.5\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"383.38\" y=\"-138.2\" font-family=\"Monospace\" font-size=\"14.00\">AGG [col(&quot;address&quot;).n_unique().alias(&quot;n_addresses&quot;), col(&quot;name&quot;).count().alias(&quot;n_people&quot;)]</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"383.38\" y=\"-120.95\" font-family=\"Monospace\" font-size=\"14.00\">BY</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"383.38\" y=\"-103.7\" font-family=\"Monospace\" font-size=\"14.00\">[col(&quot;city&quot;)]</text>\n",
       "</g>\n",
       "<!-- p2&#45;&gt;p1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>p2-&gt;p1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M383.38,-60.02C383.38,-67.7 383.38,-76.11 383.38,-84.26\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"379.88,-83.98 383.38,-93.98 386.88,-83.98 379.88,-83.98\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "query = (pl.scan_csv(\"./example.csv\")\n",
    "         .group_by(\"city\")\n",
    "         .agg(n_addresses=pl.col(\"address\").n_unique(), n_people=pl.col(\"name\").count())\n",
    "         .filter(pl.col(\"city\") == \"Amsterdam\"))\n",
    "\n",
    "query.show_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548e05b6",
   "metadata": {},
   "source": [
    "We define the data pipeline to be the same as the unimproved pd pipeline.\n",
    "However, before execuation, the polars library optimize the query plan (optimised plan should be read from bottom to top):\n",
    "1. Filter the obs with city == \"Amsterdam\" (σ stands for filtering and indicates any filter conditions)\n",
    "2. Only load the columns that will be used (π for projection and indicates choosing a subset of column, in our case, 3 out of 7)\n",
    "3. COnduct group by and aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679f693d",
   "metadata": {},
   "source": [
    "Formal illustration:\n",
    "1. The first step optimisation is called Predicate Pushdown; which means ”pushing down” filtering conditions as close as possible to the data source before processing the rest of the query.\n",
    "2. The second step optimisation is called Projection Pushdown; which means select columans that need to be read by applying a linear algebra projection matrix projecting onto the matrix representation of the dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4170b1de",
   "metadata": {},
   "source": [
    "Additional note: query optimiser of polars applies filter while the CSV is read from disk rather than reading the entire file into memory and then applying the filter.\n",
    "This further reduce memory requirement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c55ff4",
   "metadata": {},
   "source": [
    "### Loading Data in Chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe354c86",
   "metadata": {},
   "source": [
    "- With Polars, we can do lazy evaluation, but at some point we still need to load the result into memory (RAM).\n",
    "- If the data size is larger than the memory, we have to load and operate on it in chunks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8512b87b",
   "metadata": {},
   "source": [
    "In pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3231371b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>city</th>\n",
       "      <th>address</th>\n",
       "      <th>order_id</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>Name_1</td>\n",
       "      <td>Rome</td>\n",
       "      <td>Address_1</td>\n",
       "      <td>161629</td>\n",
       "      <td>2024-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Name_2</td>\n",
       "      <td>London</td>\n",
       "      <td>Address_2</td>\n",
       "      <td>428184</td>\n",
       "      <td>2024-01-01 01:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Name_3</td>\n",
       "      <td>Paris</td>\n",
       "      <td>Address_3</td>\n",
       "      <td>592734</td>\n",
       "      <td>2024-01-01 02:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Name_4</td>\n",
       "      <td>Madrid</td>\n",
       "      <td>Address_4</td>\n",
       "      <td>855195</td>\n",
       "      <td>2024-01-01 03:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2.5</td>\n",
       "      <td>Name_5</td>\n",
       "      <td>Amsterdam</td>\n",
       "      <td>Address_5</td>\n",
       "      <td>390160</td>\n",
       "      <td>2024-01-01 04:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>295</td>\n",
       "      <td>148.0</td>\n",
       "      <td>Name_296</td>\n",
       "      <td>London</td>\n",
       "      <td>Address_296</td>\n",
       "      <td>730265</td>\n",
       "      <td>2024-01-13 07:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>296</td>\n",
       "      <td>148.5</td>\n",
       "      <td>Name_297</td>\n",
       "      <td>Rome</td>\n",
       "      <td>Address_297</td>\n",
       "      <td>713157</td>\n",
       "      <td>2024-01-13 08:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>297</td>\n",
       "      <td>149.0</td>\n",
       "      <td>Name_298</td>\n",
       "      <td>Paris</td>\n",
       "      <td>Address_298</td>\n",
       "      <td>729474</td>\n",
       "      <td>2024-01-13 09:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>298</td>\n",
       "      <td>149.5</td>\n",
       "      <td>Name_299</td>\n",
       "      <td>Madrid</td>\n",
       "      <td>Address_299</td>\n",
       "      <td>921106</td>\n",
       "      <td>2024-01-13 10:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>299</td>\n",
       "      <td>150.0</td>\n",
       "      <td>Name_300</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Address_300</td>\n",
       "      <td>266926</td>\n",
       "      <td>2024-01-13 11:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0     id      name       city      address  order_id  \\\n",
       "0             0    0.5    Name_1       Rome    Address_1    161629   \n",
       "1             1    1.0    Name_2     London    Address_2    428184   \n",
       "2             2    1.5    Name_3      Paris    Address_3    592734   \n",
       "3             3    2.0    Name_4     Madrid    Address_4    855195   \n",
       "4             4    2.5    Name_5  Amsterdam    Address_5    390160   \n",
       "..          ...    ...       ...        ...          ...       ...   \n",
       "295         295  148.0  Name_296     London  Address_296    730265   \n",
       "296         296  148.5  Name_297       Rome  Address_297    713157   \n",
       "297         297  149.0  Name_298      Paris  Address_298    729474   \n",
       "298         298  149.5  Name_299     Madrid  Address_299    921106   \n",
       "299         299  150.0  Name_300     Berlin  Address_300    266926   \n",
       "\n",
       "                    time  \n",
       "0    2024-01-01 00:00:00  \n",
       "1    2024-01-01 01:00:00  \n",
       "2    2024-01-01 02:00:00  \n",
       "3    2024-01-01 03:00:00  \n",
       "4    2024-01-01 04:00:00  \n",
       "..                   ...  \n",
       "295  2024-01-13 07:00:00  \n",
       "296  2024-01-13 08:00:00  \n",
       "297  2024-01-13 09:00:00  \n",
       "298  2024-01-13 10:00:00  \n",
       "299  2024-01-13 11:00:00  \n",
       "\n",
       "[300 rows x 7 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize list to store processed chunks\n",
    "processed_chunks = []\n",
    "\n",
    "# Read and process data in chunks\n",
    "chunk_size = 1000\n",
    "for chunk in pd.read_csv('example.csv', chunksize = chunk_size):\n",
    "    # Process chunk by dividing values by 2\n",
    "    chunk['id'] = chunk['id'] / 2\n",
    "    # Store processed chunk\n",
    "    processed_chunks.append(chunk)\n",
    "\n",
    "# Combine all processed chunks into final result\n",
    "final_result = pd.concat(processed_chunks, ignore_index=True)\n",
    "final_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552bb49f",
   "metadata": {},
   "source": [
    "In Polars:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab89f1a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qb/pd0pzd3x0jj2c_2nkn2hmrxw0000gn/T/ipykernel_19880/794258352.py:4: DeprecationWarning: the `streaming` parameter was deprecated in 1.25.0; use `engine` instead.\n",
      "  .collect(streaming=True)) # Use streaming in collect to process in chunks\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (300, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th></th><th>id</th><th>name</th><th>city</th><th>address</th><th>order_id</th><th>time</th></tr><tr><td>i64</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>i64</td><td>str</td></tr></thead><tbody><tr><td>0</td><td>0.5</td><td>&quot;Name_1&quot;</td><td>&quot;Rome&quot;</td><td>&quot;Address_1&quot;</td><td>161629</td><td>&quot;2024-01-01 00:00:00&quot;</td></tr><tr><td>1</td><td>1.0</td><td>&quot;Name_2&quot;</td><td>&quot;London&quot;</td><td>&quot;Address_2&quot;</td><td>428184</td><td>&quot;2024-01-01 01:00:00&quot;</td></tr><tr><td>2</td><td>1.5</td><td>&quot;Name_3&quot;</td><td>&quot;Paris&quot;</td><td>&quot;Address_3&quot;</td><td>592734</td><td>&quot;2024-01-01 02:00:00&quot;</td></tr><tr><td>3</td><td>2.0</td><td>&quot;Name_4&quot;</td><td>&quot;Madrid&quot;</td><td>&quot;Address_4&quot;</td><td>855195</td><td>&quot;2024-01-01 03:00:00&quot;</td></tr><tr><td>4</td><td>2.5</td><td>&quot;Name_5&quot;</td><td>&quot;Amsterdam&quot;</td><td>&quot;Address_5&quot;</td><td>390160</td><td>&quot;2024-01-01 04:00:00&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>295</td><td>148.0</td><td>&quot;Name_296&quot;</td><td>&quot;London&quot;</td><td>&quot;Address_296&quot;</td><td>730265</td><td>&quot;2024-01-13 07:00:00&quot;</td></tr><tr><td>296</td><td>148.5</td><td>&quot;Name_297&quot;</td><td>&quot;Rome&quot;</td><td>&quot;Address_297&quot;</td><td>713157</td><td>&quot;2024-01-13 08:00:00&quot;</td></tr><tr><td>297</td><td>149.0</td><td>&quot;Name_298&quot;</td><td>&quot;Paris&quot;</td><td>&quot;Address_298&quot;</td><td>729474</td><td>&quot;2024-01-13 09:00:00&quot;</td></tr><tr><td>298</td><td>149.5</td><td>&quot;Name_299&quot;</td><td>&quot;Madrid&quot;</td><td>&quot;Address_299&quot;</td><td>921106</td><td>&quot;2024-01-13 10:00:00&quot;</td></tr><tr><td>299</td><td>150.0</td><td>&quot;Name_300&quot;</td><td>&quot;Berlin&quot;</td><td>&quot;Address_300&quot;</td><td>266926</td><td>&quot;2024-01-13 11:00:00&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (300, 7)\n",
       "┌─────┬───────┬──────────┬───────────┬─────────────┬──────────┬─────────────────────┐\n",
       "│     ┆ id    ┆ name     ┆ city      ┆ address     ┆ order_id ┆ time                │\n",
       "│ --- ┆ ---   ┆ ---      ┆ ---       ┆ ---         ┆ ---      ┆ ---                 │\n",
       "│ i64 ┆ f64   ┆ str      ┆ str       ┆ str         ┆ i64      ┆ str                 │\n",
       "╞═════╪═══════╪══════════╪═══════════╪═════════════╪══════════╪═════════════════════╡\n",
       "│ 0   ┆ 0.5   ┆ Name_1   ┆ Rome      ┆ Address_1   ┆ 161629   ┆ 2024-01-01 00:00:00 │\n",
       "│ 1   ┆ 1.0   ┆ Name_2   ┆ London    ┆ Address_2   ┆ 428184   ┆ 2024-01-01 01:00:00 │\n",
       "│ 2   ┆ 1.5   ┆ Name_3   ┆ Paris     ┆ Address_3   ┆ 592734   ┆ 2024-01-01 02:00:00 │\n",
       "│ 3   ┆ 2.0   ┆ Name_4   ┆ Madrid    ┆ Address_4   ┆ 855195   ┆ 2024-01-01 03:00:00 │\n",
       "│ 4   ┆ 2.5   ┆ Name_5   ┆ Amsterdam ┆ Address_5   ┆ 390160   ┆ 2024-01-01 04:00:00 │\n",
       "│ …   ┆ …     ┆ …        ┆ …         ┆ …           ┆ …        ┆ …                   │\n",
       "│ 295 ┆ 148.0 ┆ Name_296 ┆ London    ┆ Address_296 ┆ 730265   ┆ 2024-01-13 07:00:00 │\n",
       "│ 296 ┆ 148.5 ┆ Name_297 ┆ Rome      ┆ Address_297 ┆ 713157   ┆ 2024-01-13 08:00:00 │\n",
       "│ 297 ┆ 149.0 ┆ Name_298 ┆ Paris     ┆ Address_298 ┆ 729474   ┆ 2024-01-13 09:00:00 │\n",
       "│ 298 ┆ 149.5 ┆ Name_299 ┆ Madrid    ┆ Address_299 ┆ 921106   ┆ 2024-01-13 10:00:00 │\n",
       "│ 299 ┆ 150.0 ┆ Name_300 ┆ Berlin    ┆ Address_300 ┆ 266926   ┆ 2024-01-13 11:00:00 │\n",
       "└─────┴───────┴──────────┴───────────┴─────────────┴──────────┴─────────────────────┘"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read and process data using Polars streaming\n",
    "result = (pl.scan_csv('example.csv')\n",
    "          .with_columns(pl.col('id') / 2)\n",
    "          .collect(streaming=True)) # Use streaming in collect to process in chunks\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f242867",
   "metadata": {},
   "source": [
    "In Polars, the size of the batch/chunk is automatically determined by:\n",
    "- The number of CPUs on your machine\n",
    "- The amount of memory each row in your query requires"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac84a0bf",
   "metadata": {},
   "source": [
    "If the data wrangling result does not fit into memory either, we can write the output directly to a file on disk using the sink_methods (this is actually very useful, and something that only database frameworks but not data wrangling frameworks could do): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f75a3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "query.sink_parquet(\"example.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8041ee81",
   "metadata": {},
   "source": [
    "## Database Management Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1944484",
   "metadata": {},
   "source": [
    "- A big advantage of database management system is that it automatically conducts above data retrieval optimization, including chunking, predicate and projection pushdowns.\n",
    "- Beyond that, relational databases contain more information on the data, such as relationships among tables and indexes, to speed up the data retrieval and make storage more secure.\n",
    "- We communicated with a database using a programming language called SQL (structured query language)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f13402",
   "metadata": {},
   "source": [
    "### Relational Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac834720",
   "metadata": {},
   "source": [
    "- A relational database is a type of database that stores and organises data in tables with predefined **relationships** between them based on **keys**.\n",
    "- Each table in the relational database have a **primary key**, which uniquely identifies every row in the table.\n",
    "- Some of the table also has **foreign key**, which refers to the primary key of another table.\n",
    "- Tables are connected through primary–foreign key relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb80cdbd",
   "metadata": {},
   "source": [
    "Consider an example of a database for an e-commerce platform with two tables:\n",
    "- Customer table: the primary key is customer_id, other columns store customer information.\n",
    "- Order table: the primary key is order_id, the foreign key is customer_id, representing the customer and make the order; the other columns store other order information.\n",
    "- The two tables can be connected through customer_id: customer_id is primary key in customer table, and it is foreign key in order table.\n",
    "- The relationship between these two tables is 1:n, since one customer can make several orders (1 customer_id can be mapped to N order_id since there are duplicated customer_id in the order table)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed26f377",
   "metadata": {},
   "source": [
    "![my plot](graphs/relation_database.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a241b1",
   "metadata": {},
   "source": [
    "### Structured Query Language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0824ae2",
   "metadata": {},
   "source": [
    "- SQL is a programming language to store and work with data in a relation database.\n",
    "- When receiving a SQL query, the query processor of the database management system creates a plan for retrieving or writing data in the most effective way.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5c8650",
   "metadata": {},
   "source": [
    "SQL syntax:\n",
    "* SQL is not case sensitive, but it is best practice to write the commands in uppercase.\n",
    "* SQL queries have to be written in a specific order: SELECT ... FROM ... WHERE ... GROUP BY ... HAVIN ... ORDER BY ... LIMIT ...\n",
    "    * SELECT ... FROM ... retrieve specified columns from a deisgnated table\n",
    "    * WHERE filters individual rows (before they’re grouped, if there is a GROUP BY followed)\n",
    "    * GROUP BY groups data based on unique combination of one/more columns for computing aggregated measures (aggregation operation: count(*), max(col_name), min(col_name), avg(col_name),...)\n",
    "    * HAVING filters groups after the GROUP BY\n",
    "    * ORDER BY ... sort the result based on some column\n",
    "    * LIMIT ... limit the result for first n rows\n",
    "* Equality is written with ”col_1=2” and not ”col_1 == 2”\n",
    "* To check whether a column has NULL entries, write ”col_1 IS NULL” rather than ”col_1 = NULL\"\n",
    "* Limit queries to test code: SELECT * FROM my_table LIMIT 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1332a99",
   "metadata": {},
   "source": [
    "### How Database Optimize Data Retrieval\n",
    "1. Automatically optimize query plan: adjust order of operation, conduct chunking, predicate and projection pushdowns\n",
    "2. Construct a tree structure of indexes to make data retrieval quicker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce9dd5f",
   "metadata": {},
   "source": [
    "Three structure of indexes:\n",
    "* We can specify which columns are indexes when creating a table using database management system.\n",
    "* The database engine will automatically build a tree structure for the indexed column, optimize tree depth and values to split to speed up data retrival.\n",
    "* Suppose \"name\" is an index of the table; conceptually, we can think of the index as grouping values alphabetically. \n",
    "    * For example, the upper levels of the tree might divide names into ranges such as A–C, D–F, G–I, and so on. \n",
    "    * Lower levels further narrow these ranges (Da–Df, Dg–Dl, etc.); the actual structure is optimized by the database engine.\n",
    "* When we exectue the query: SELECT * FROM table_name WHERE name = ’Darcy’, the database will not scan all rows to find the row with name = mr darcy. Instead, it follows the tree:\n",
    "    * It selects the branch containing the range that includes “D”.\n",
    "    * It moves to the next layer where the range is further narrowed, such as Da–De.\n",
    "    * It continues descending until it reaches the leaf node containing “Darcy”.\n",
    "* As a result, the number of operations is proportional to the height of the B-tree, typically only 3–6 steps (log(N)) even for millions of rows, instead of scanning N rows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c722d11",
   "metadata": {},
   "source": [
    "### Python and Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610f6931",
   "metadata": {},
   "source": [
    "How to load SQL query result to a pd dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e947a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season_id</th>\n",
       "      <th>team_id_home</th>\n",
       "      <th>team_abbreviation_home</th>\n",
       "      <th>team_name_home</th>\n",
       "      <th>game_id</th>\n",
       "      <th>game_date</th>\n",
       "      <th>matchup_home</th>\n",
       "      <th>wl_home</th>\n",
       "      <th>min</th>\n",
       "      <th>fgm_home</th>\n",
       "      <th>...</th>\n",
       "      <th>reb_away</th>\n",
       "      <th>ast_away</th>\n",
       "      <th>stl_away</th>\n",
       "      <th>blk_away</th>\n",
       "      <th>tov_away</th>\n",
       "      <th>pf_away</th>\n",
       "      <th>pts_away</th>\n",
       "      <th>plus_minus_away</th>\n",
       "      <th>video_available_away</th>\n",
       "      <th>season_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21946</td>\n",
       "      <td>1610610035</td>\n",
       "      <td>HUS</td>\n",
       "      <td>Toronto Huskies</td>\n",
       "      <td>0024600001</td>\n",
       "      <td>1946-11-01 00:00:00</td>\n",
       "      <td>HUS vs. NYK</td>\n",
       "      <td>L</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Regular Season</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21946</td>\n",
       "      <td>1610610034</td>\n",
       "      <td>BOM</td>\n",
       "      <td>St. Louis Bombers</td>\n",
       "      <td>0024600003</td>\n",
       "      <td>1946-11-02 00:00:00</td>\n",
       "      <td>BOM vs. PIT</td>\n",
       "      <td>W</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>25.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>-5</td>\n",
       "      <td>0</td>\n",
       "      <td>Regular Season</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21946</td>\n",
       "      <td>1610610032</td>\n",
       "      <td>PRO</td>\n",
       "      <td>Providence Steamrollers</td>\n",
       "      <td>0024600002</td>\n",
       "      <td>1946-11-02 00:00:00</td>\n",
       "      <td>PRO vs. BOS</td>\n",
       "      <td>W</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>-6</td>\n",
       "      <td>0</td>\n",
       "      <td>Regular Season</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21946</td>\n",
       "      <td>1610610025</td>\n",
       "      <td>CHS</td>\n",
       "      <td>Chicago Stags</td>\n",
       "      <td>0024600004</td>\n",
       "      <td>1946-11-02 00:00:00</td>\n",
       "      <td>CHS vs. NYK</td>\n",
       "      <td>W</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>22.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>-16</td>\n",
       "      <td>0</td>\n",
       "      <td>Regular Season</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21946</td>\n",
       "      <td>1610610028</td>\n",
       "      <td>DEF</td>\n",
       "      <td>Detroit Falcons</td>\n",
       "      <td>0024600005</td>\n",
       "      <td>1946-11-02 00:00:00</td>\n",
       "      <td>DEF vs. WAS</td>\n",
       "      <td>L</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>Regular Season</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>21946</td>\n",
       "      <td>1610610026</td>\n",
       "      <td>CLR</td>\n",
       "      <td>Cleveland Rebels</td>\n",
       "      <td>0024600006</td>\n",
       "      <td>1946-11-03 00:00:00</td>\n",
       "      <td>CLR vs. HUS</td>\n",
       "      <td>W</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.0</td>\n",
       "      <td>-11</td>\n",
       "      <td>0</td>\n",
       "      <td>Regular Season</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>21946</td>\n",
       "      <td>1610610031</td>\n",
       "      <td>PIT</td>\n",
       "      <td>Pittsburgh Ironmen</td>\n",
       "      <td>0024600007</td>\n",
       "      <td>1946-11-04 00:00:00</td>\n",
       "      <td>PIT vs. WAS</td>\n",
       "      <td>L</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>Regular Season</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>21946</td>\n",
       "      <td>1610612738</td>\n",
       "      <td>BOS</td>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>0024600008</td>\n",
       "      <td>1946-11-05 00:00:00</td>\n",
       "      <td>BOS vs. CHS</td>\n",
       "      <td>L</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Regular Season</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>21946</td>\n",
       "      <td>1610610028</td>\n",
       "      <td>DEF</td>\n",
       "      <td>Detroit Falcons</td>\n",
       "      <td>0024600009</td>\n",
       "      <td>1946-11-05 00:00:00</td>\n",
       "      <td>DEF vs. BOM</td>\n",
       "      <td>L</td>\n",
       "      <td>0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Regular Season</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>21946</td>\n",
       "      <td>1610610032</td>\n",
       "      <td>PRO</td>\n",
       "      <td>Providence Steamrollers</td>\n",
       "      <td>0024600011</td>\n",
       "      <td>1946-11-07 00:00:00</td>\n",
       "      <td>PRO vs. CHS</td>\n",
       "      <td>W</td>\n",
       "      <td>0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>14.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>-8</td>\n",
       "      <td>0</td>\n",
       "      <td>Regular Season</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  season_id team_id_home team_abbreviation_home           team_name_home  \\\n",
       "0     21946   1610610035                    HUS          Toronto Huskies   \n",
       "1     21946   1610610034                    BOM        St. Louis Bombers   \n",
       "2     21946   1610610032                    PRO  Providence Steamrollers   \n",
       "3     21946   1610610025                    CHS            Chicago Stags   \n",
       "4     21946   1610610028                    DEF          Detroit Falcons   \n",
       "5     21946   1610610026                    CLR         Cleveland Rebels   \n",
       "6     21946   1610610031                    PIT       Pittsburgh Ironmen   \n",
       "7     21946   1610612738                    BOS           Boston Celtics   \n",
       "8     21946   1610610028                    DEF          Detroit Falcons   \n",
       "9     21946   1610610032                    PRO  Providence Steamrollers   \n",
       "\n",
       "      game_id            game_date matchup_home wl_home  min  fgm_home  ...  \\\n",
       "0  0024600001  1946-11-01 00:00:00  HUS vs. NYK       L    0      25.0  ...   \n",
       "1  0024600003  1946-11-02 00:00:00  BOM vs. PIT       W    0      20.0  ...   \n",
       "2  0024600002  1946-11-02 00:00:00  PRO vs. BOS       W    0      21.0  ...   \n",
       "3  0024600004  1946-11-02 00:00:00  CHS vs. NYK       W    0      21.0  ...   \n",
       "4  0024600005  1946-11-02 00:00:00  DEF vs. WAS       L    0      10.0  ...   \n",
       "5  0024600006  1946-11-03 00:00:00  CLR vs. HUS       W    0      24.0  ...   \n",
       "6  0024600007  1946-11-04 00:00:00  PIT vs. WAS       L    0      19.0  ...   \n",
       "7  0024600008  1946-11-05 00:00:00  BOS vs. CHS       L    0      23.0  ...   \n",
       "8  0024600009  1946-11-05 00:00:00  DEF vs. BOM       L    0      18.0  ...   \n",
       "9  0024600011  1946-11-07 00:00:00  PRO vs. CHS       W    0      31.0  ...   \n",
       "\n",
       "   reb_away  ast_away stl_away blk_away tov_away  pf_away  pts_away  \\\n",
       "0      None      None     None     None     None      NaN      68.0   \n",
       "1      None      None     None     None     None     25.0      51.0   \n",
       "2      None      None     None     None     None      NaN      53.0   \n",
       "3      None      None     None     None     None     22.0      47.0   \n",
       "4      None      None     None     None     None      NaN      50.0   \n",
       "5      None      None     None     None     None      NaN      60.0   \n",
       "6      None      None     None     None     None      NaN      71.0   \n",
       "7      None      None     None     None     None      NaN      57.0   \n",
       "8      None      None     None     None     None      NaN      53.0   \n",
       "9      None      None     None     None     None     14.0      65.0   \n",
       "\n",
       "   plus_minus_away video_available_away     season_type  \n",
       "0                2                    0  Regular Season  \n",
       "1               -5                    0  Regular Season  \n",
       "2               -6                    0  Regular Season  \n",
       "3              -16                    0  Regular Season  \n",
       "4               17                    0  Regular Season  \n",
       "5              -11                    0  Regular Season  \n",
       "6               15                    0  Regular Season  \n",
       "7                2                    0  Regular Season  \n",
       "8                4                    0  Regular Season  \n",
       "9               -8                    0  Regular Season  \n",
       "\n",
       "[10 rows x 55 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlite3 as sql\n",
    "con = sql.connect(\"example_database/nba.sqlite\") #connect to the database\n",
    "df_games = pd.read_sql(\"SELECT * FROM game LIMIT 10\", con) #execute sql query, save to pd dataframe\n",
    "df_games"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8eb079a",
   "metadata": {},
   "source": [
    "For complex SQL query, we may want to create temporary tables to simplify the data wrangling pipeline:\n",
    "- we can create a temporary table on disk with SQL (not with pandas)\n",
    "- temporary tables are only stored during the sqlite session\n",
    "- we can also create a ”View” which is stored even when we close the session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64d2b30b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season_id</th>\n",
       "      <th>team_id_home</th>\n",
       "      <th>team_abbreviation_home</th>\n",
       "      <th>team_name_home</th>\n",
       "      <th>game_id</th>\n",
       "      <th>game_date</th>\n",
       "      <th>matchup_home</th>\n",
       "      <th>wl_home</th>\n",
       "      <th>min</th>\n",
       "      <th>fgm_home</th>\n",
       "      <th>...</th>\n",
       "      <th>stl_away</th>\n",
       "      <th>blk_away</th>\n",
       "      <th>tov_away</th>\n",
       "      <th>pf_away</th>\n",
       "      <th>pts_away</th>\n",
       "      <th>plus_minus_away</th>\n",
       "      <th>video_available_away</th>\n",
       "      <th>season_type</th>\n",
       "      <th>game_id</th>\n",
       "      <th>number_of_plays</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42003</td>\n",
       "      <td>1610612765</td>\n",
       "      <td>DET</td>\n",
       "      <td>Detroit Pistons</td>\n",
       "      <td>0040300215</td>\n",
       "      <td>2004-05-14 00:00:00</td>\n",
       "      <td>DET vs. NJN</td>\n",
       "      <td>L</td>\n",
       "      <td>315</td>\n",
       "      <td>42.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>Playoffs</td>\n",
       "      <td>0040300215</td>\n",
       "      <td>673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42010</td>\n",
       "      <td>1610612763</td>\n",
       "      <td>MEM</td>\n",
       "      <td>Memphis Grizzlies</td>\n",
       "      <td>0041000224</td>\n",
       "      <td>2011-05-09 00:00:00</td>\n",
       "      <td>MEM vs. OKC</td>\n",
       "      <td>L</td>\n",
       "      <td>315</td>\n",
       "      <td>40.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>Playoffs</td>\n",
       "      <td>0041000224</td>\n",
       "      <td>653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42018</td>\n",
       "      <td>1610612757</td>\n",
       "      <td>POR</td>\n",
       "      <td>Portland Trail Blazers</td>\n",
       "      <td>0041800233</td>\n",
       "      <td>2019-05-03 00:00:00</td>\n",
       "      <td>POR vs. DEN</td>\n",
       "      <td>W</td>\n",
       "      <td>340</td>\n",
       "      <td>52.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>-3</td>\n",
       "      <td>1</td>\n",
       "      <td>Playoffs</td>\n",
       "      <td>0041800233</td>\n",
       "      <td>634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42012</td>\n",
       "      <td>1610612741</td>\n",
       "      <td>CHI</td>\n",
       "      <td>Chicago Bulls</td>\n",
       "      <td>0041200134</td>\n",
       "      <td>2013-04-27 00:00:00</td>\n",
       "      <td>CHI vs. BKN</td>\n",
       "      <td>W</td>\n",
       "      <td>315</td>\n",
       "      <td>58.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>-8</td>\n",
       "      <td>1</td>\n",
       "      <td>Playoffs</td>\n",
       "      <td>0041200134</td>\n",
       "      <td>623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42013</td>\n",
       "      <td>1610612745</td>\n",
       "      <td>HOU</td>\n",
       "      <td>Houston Rockets</td>\n",
       "      <td>0041300171</td>\n",
       "      <td>2014-04-20 00:00:00</td>\n",
       "      <td>HOU vs. POR</td>\n",
       "      <td>L</td>\n",
       "      <td>265</td>\n",
       "      <td>43.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Playoffs</td>\n",
       "      <td>0041300171</td>\n",
       "      <td>618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>42008</td>\n",
       "      <td>1610612741</td>\n",
       "      <td>CHI</td>\n",
       "      <td>Chicago Bulls</td>\n",
       "      <td>0040800116</td>\n",
       "      <td>2009-04-30 00:00:00</td>\n",
       "      <td>CHI vs. BOS</td>\n",
       "      <td>W</td>\n",
       "      <td>315</td>\n",
       "      <td>49.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>Playoffs</td>\n",
       "      <td>0040800116</td>\n",
       "      <td>606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>42018</td>\n",
       "      <td>1610612761</td>\n",
       "      <td>TOR</td>\n",
       "      <td>Toronto Raptors</td>\n",
       "      <td>0041800303</td>\n",
       "      <td>2019-05-19 00:00:00</td>\n",
       "      <td>TOR vs. MIL</td>\n",
       "      <td>W</td>\n",
       "      <td>290</td>\n",
       "      <td>40.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>-6</td>\n",
       "      <td>1</td>\n",
       "      <td>Playoffs</td>\n",
       "      <td>0041800303</td>\n",
       "      <td>606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>42008</td>\n",
       "      <td>1610612741</td>\n",
       "      <td>CHI</td>\n",
       "      <td>Chicago Bulls</td>\n",
       "      <td>0040800114</td>\n",
       "      <td>2009-04-26 00:00:00</td>\n",
       "      <td>CHI vs. BOS</td>\n",
       "      <td>W</td>\n",
       "      <td>290</td>\n",
       "      <td>45.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>-3</td>\n",
       "      <td>0</td>\n",
       "      <td>Playoffs</td>\n",
       "      <td>0040800114</td>\n",
       "      <td>596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>42004</td>\n",
       "      <td>1610612751</td>\n",
       "      <td>NJN</td>\n",
       "      <td>New Jersey Nets</td>\n",
       "      <td>0040400103</td>\n",
       "      <td>2005-04-28 00:00:00</td>\n",
       "      <td>NJN vs. MIA</td>\n",
       "      <td>L</td>\n",
       "      <td>290</td>\n",
       "      <td>42.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Playoffs</td>\n",
       "      <td>0040400103</td>\n",
       "      <td>593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>42006</td>\n",
       "      <td>1610612765</td>\n",
       "      <td>DET</td>\n",
       "      <td>Detroit Pistons</td>\n",
       "      <td>0040600305</td>\n",
       "      <td>2007-05-31 00:00:00</td>\n",
       "      <td>DET vs. CLE</td>\n",
       "      <td>L</td>\n",
       "      <td>290</td>\n",
       "      <td>34.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Playoffs</td>\n",
       "      <td>0040600305</td>\n",
       "      <td>583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  season_id team_id_home team_abbreviation_home          team_name_home  \\\n",
       "0     42003   1610612765                    DET         Detroit Pistons   \n",
       "1     42010   1610612763                    MEM       Memphis Grizzlies   \n",
       "2     42018   1610612757                    POR  Portland Trail Blazers   \n",
       "3     42012   1610612741                    CHI           Chicago Bulls   \n",
       "4     42013   1610612745                    HOU         Houston Rockets   \n",
       "5     42008   1610612741                    CHI           Chicago Bulls   \n",
       "6     42018   1610612761                    TOR         Toronto Raptors   \n",
       "7     42008   1610612741                    CHI           Chicago Bulls   \n",
       "8     42004   1610612751                    NJN         New Jersey Nets   \n",
       "9     42006   1610612765                    DET         Detroit Pistons   \n",
       "\n",
       "      game_id            game_date matchup_home wl_home  min  fgm_home  ...  \\\n",
       "0  0040300215  2004-05-14 00:00:00  DET vs. NJN       L  315      42.0  ...   \n",
       "1  0041000224  2011-05-09 00:00:00  MEM vs. OKC       L  315      40.0  ...   \n",
       "2  0041800233  2019-05-03 00:00:00  POR vs. DEN       W  340      52.0  ...   \n",
       "3  0041200134  2013-04-27 00:00:00  CHI vs. BKN       W  315      58.0  ...   \n",
       "4  0041300171  2014-04-20 00:00:00  HOU vs. POR       L  265      43.0  ...   \n",
       "5  0040800116  2009-04-30 00:00:00  CHI vs. BOS       W  315      49.0  ...   \n",
       "6  0041800303  2019-05-19 00:00:00  TOR vs. MIL       W  290      40.0  ...   \n",
       "7  0040800114  2009-04-26 00:00:00  CHI vs. BOS       W  290      45.0  ...   \n",
       "8  0040400103  2005-04-28 00:00:00  NJN vs. MIA       L  290      42.0  ...   \n",
       "9  0040600305  2007-05-31 00:00:00  DET vs. CLE       L  290      34.0  ...   \n",
       "\n",
       "   stl_away  blk_away  tov_away  pf_away  pts_away  plus_minus_away  \\\n",
       "0       8.0       9.0      34.0     42.0     127.0                7   \n",
       "1       9.0       8.0      18.0     31.0     133.0               10   \n",
       "2      11.0       8.0      21.0     27.0     137.0               -3   \n",
       "3       7.0      10.0      20.0     27.0     134.0               -8   \n",
       "4       7.0       6.0      12.0     32.0     122.0                2   \n",
       "5       6.0       6.0      13.0     29.0     127.0               -1   \n",
       "6      14.0       5.0      20.0     30.0     112.0               -6   \n",
       "7      10.0       4.0      21.0     31.0     118.0               -3   \n",
       "8       9.0       3.0      18.0     25.0     108.0                3   \n",
       "9       8.0       5.0      14.0     36.0     109.0                2   \n",
       "\n",
       "   video_available_away  season_type     game_id  number_of_plays  \n",
       "0                     0     Playoffs  0040300215              673  \n",
       "1                     0     Playoffs  0041000224              653  \n",
       "2                     1     Playoffs  0041800233              634  \n",
       "3                     1     Playoffs  0041200134              623  \n",
       "4                     1     Playoffs  0041300171              618  \n",
       "5                     0     Playoffs  0040800116              606  \n",
       "6                     1     Playoffs  0041800303              606  \n",
       "7                     0     Playoffs  0040800114              596  \n",
       "8                     0     Playoffs  0040400103              593  \n",
       "9                     0     Playoffs  0040600305              583  \n",
       "\n",
       "[10 rows x 57 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what were the top 10 games with the most plays?\n",
    "import sqlite3 as sql\n",
    "con = sql.connect(\"example_database/nba.sqlite\")\n",
    "\n",
    "query = \"\"\"\n",
    "CREATE TEMPORARY TABLE plays_per_game AS\n",
    "    SELECT game_id, COUNT(*) AS number_of_plays\n",
    "    FROM play_by_play\n",
    "    GROUP BY game_id\n",
    "\"\"\"\n",
    "con.execute(query)\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM game AS g\n",
    "LEFT JOIN plays_per_game AS ppg\n",
    "    ON g.game_id = ppg.game_id\n",
    "WHERE season_type = 'Playoffs'\n",
    "ORDER BY ppg.number_of_plays DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql(query, con)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c376ca4",
   "metadata": {},
   "source": [
    "Write Pandas data frames to the DB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b7c3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3 as sql\n",
    "con = sql.connect(\"nba.sqlite\")\n",
    "df_games.to_sql(\"top_10\", con) #\"top_10\" is the new table name in the database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a84034",
   "metadata": {},
   "source": [
    "Create new table (empty) with sqlite3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af22b30c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x12d398ec0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con = sql.connect(\"nba.sqlite\") #the nba.sqlite file store the complete database, the csv folder is only used to illustarte what tables are presented in the database (not updated)\n",
    "con.execute(\"CREATE TABLE salaries(player_id, year, salary)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ae0fd5",
   "metadata": {},
   "source": [
    "Build a new database with sqlite3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c3eb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_new = sql.connect(\"new.sqlite\")\n",
    "con_new.execute(\"CREATE TABLE movie(title, score)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcf666a",
   "metadata": {},
   "source": [
    "Close connection to sqlite3 database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9b3eeab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1328d14c",
   "metadata": {},
   "source": [
    "**DuckDB:**\n",
    "- An alternative database system that allows us to create database and write query using Python\n",
    "- The DuckDB can query parquet and csv using SQL directly\n",
    "- It adopts hive partitioning strategy; if detected data files are in a hive partitioned hierarchy, filters on the partition keys are automatically pushed down\n",
    "- This way the system skips reading files that are not necessary to answer a query"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8d78af1a",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "orders\n",
    "├── year 2011\n",
    "│   ├── month=1\n",
    "│   │   └── file1.parquet\n",
    "│   ├── month=2\n",
    "│   │   └── file2.parquet\n",
    "│   ├── month=3\n",
    "│   │   └── file3.parquet\n",
    "│   ├── month=4\n",
    "│   │   └── file4.parquet\n",
    "│   └── month=5\n",
    "│       └── file5.parquet\n",
    "└── year 2022\n",
    "    ├── month=1\n",
    "    │   └── file6.parquet\n",
    "    ├── month=2\n",
    "    │   └── file7.parquet\n",
    "    ├── month=3\n",
    "    │   └── file8.parquet\n",
    "    ├── month=4\n",
    "    │   └── file9.parquet\n",
    "    └── month=5\n",
    "        └── file10.parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffdb437",
   "metadata": {},
   "source": [
    "Read parquet using DuckDB:\n",
    "- Suppose that the order table is stored as parquet files in the order folder, with folder structure above.\n",
    "- Within each folder, the partition key has a value that is determined by the name of the folder.\n",
    "- DuckDB can automatically detect these partion keys, it will create two additional columns for partion keys \"year\" and \"month\", when reading the parquet files.\n",
    "- When filtering on the partion keys in the SQL query, e.g. filter on \"year = 2022 AND month = 5\", the DuckDB only read parquet files in the path orders/year 2022/month 5 (as these files are the only necessary ones to answer the query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630a6324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of reading parquet using DuckDB and filtering on partion keys\n",
    "import duckdb as ddb\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT * \n",
    "    FROM read_parquet('orders/*/*/*.parquet')\n",
    "    WHERE year = 2022 \n",
    "        AND month = 5\n",
    "\"\"\"\n",
    "con = ddb.connect()\n",
    "con.sql(query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18091992",
   "metadata": {},
   "source": [
    "DuckDB can also create a database from parquet file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d510321",
   "metadata": {},
   "outputs": [],
   "source": [
    "con = ddb.connect(\"new_database.ddb\")\n",
    "\n",
    "query = \"\"\"\n",
    "    CREATE TABLE nyc_taxi \n",
    "    AS\n",
    "        SELECT * \n",
    "        FROM read_parquet('orders/*/*/*.parquet')\n",
    "        WHERE year = 2022 \n",
    "            AND month = 5\n",
    "\"\"\"\n",
    "\n",
    "con.sql(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d324073",
   "metadata": {},
   "source": [
    "## Data Storage and Management Landscape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1384fe",
   "metadata": {},
   "source": [
    "Data management concepts:\n",
    "1. Database management system: store structured data in a relational database (tables linked through primary keys and foriegn keys), include an engine to interpret and execute SQL query, optimize query plans for both data retrieval and writting.\n",
    "2. Data warehouse: store structured data generated through scheduled ETL (extract, transform, load) processes that are implmented on database (source of data), often adopt a distributed file system (data files save on different machines), and optimize for analytical queries (such as aggregation) not for frequent write/update operation\n",
    "3. Data lake: store both structed and unstructured data in files, often adopt distributed file system, optimize for cheap and flexible large scale storage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f8c3e3",
   "metadata": {},
   "source": [
    "## Extra on Python Development Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682f6626",
   "metadata": {},
   "source": [
    "### .gitignore\n",
    "Tell Git to ignore certain files in the repo:\n",
    "- Large data files\n",
    "- API keys\n",
    "- Graphs (.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63d3024",
   "metadata": {},
   "source": [
    "### Type Hints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2a6d07",
   "metadata": {},
   "source": [
    "A method to specify what should go in and what should come out for a function (specify input data type and output data type):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d05831e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_two_numbers(a: int, b: int) -> int:\n",
    "    return a * b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50dc0d63",
   "metadata": {},
   "source": [
    "Type hints with default arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5729c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greet(name: str = \"World\") -> str:\n",
    "    return f\"Hello, {name}!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ed1e06",
   "metadata": {},
   "source": [
    "Some data types for function input are not available natively, but we can easily extend types by using typing package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab67e16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "def some_funct(a: List[int]) -> List[str]:\n",
    "    return [str(x) for x in a]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57096678",
   "metadata": {},
   "source": [
    "Cheatsheet for built in types: https://mypy.readthedocs.io/en/stable/cheat_sheet_py3.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0410baa2",
   "metadata": {},
   "source": [
    "Note: \n",
    "- Python’s type hints don’t enforce types by themselves\n",
    "- But, they’re valuable for documentation\n",
    "- And we can use hook in pre-commit to conduct type checking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a44572d",
   "metadata": {},
   "source": [
    "### pre-commit\n",
    "- Pre-commit is a Python package; it runs every listed hook (represent a script) in the .pre-commit-config.yaml file to conduct some checking\n",
    "- Common checks include: if our code follows certain standards (line length of 80 or no trailing white space), and if type hints present in functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01902ea5",
   "metadata": {},
   "source": [
    "Install pre-commit:\n",
    "1. pip install pre-commit #install package\n",
    "2. pre-commit sample-config > .pre-commit-config.yaml #generate a template of config file, we need to add hook into this file\n",
    "3. pre-commit install #install all hooks we listed in the config file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbe7197",
   "metadata": {},
   "source": [
    "Example of a .pre-commit-config.yaml file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc09a0af",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# See https://pre-commit.com for more information\n",
    "# See https://pre-commit.com/hooks.html for more hooks\n",
    "repos:\n",
    "  - repo: https://github.com/pre-commit/pre-commit-hooks #github repo of pre-commit package\n",
    "    rev: v3.2.0\n",
    "    hooks: #these hooks are necessary\n",
    "      - id: trailing-whitespace\n",
    "      - id: end-of-file-fixer\n",
    "      - id: check-yaml\n",
    "      - id: check-added-large-files\n",
    "  - repo: https://github.com/PyCQA/flake8 # url to the github repo for aditional hook that we want to install, e.g. flake8\n",
    "    rev: 7.1.1 # release tag of the version we want to install\n",
    "    hooks:\n",
    "      - id: flake8 # name of the hook we want to install (repo, rev, id are necessary for all hooks we want to install)\n",
    "  - repo: https://github.com/pre-commit/mirrors-mypy # if type hints are provided, mypy checks whether the input of functiosn have correct types\n",
    "    rev: v1.13.0\n",
    "    hooks:\n",
    "      - id: mypy\n",
    "        additional_dependencies: [types-seaborn, polars, pandas-stubs, matplotlib]\n",
    "        args: [\"--ignore-missing-imports\", \"--strict\"]\n",
    "  - repo: https://github.com/kynan/nbstripout #this hook strip out juypter notebook output\n",
    "    rev: 0.7.1\n",
    "    hooks:\n",
    "      - id: nbstripout\n",
    "  - repo: https://github.com/psf/black #this hook conduct automatic formating for our script\n",
    "    rev: 23.12.1\n",
    "    hooks:\n",
    "      - id: black\n",
    "        args: [--line-length=79] # Match flake8's default line length\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4ea128",
   "metadata": {},
   "source": [
    "Pre-commit will run all hooks every time we want to commit:\n",
    "- When they find an error we will have to ”git add” them and then run the commit again\n",
    "- Or if the error is not automatically fixed, we have to first fix it, ”git add”, and then ”git commit” again"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba6a7ac",
   "metadata": {},
   "source": [
    "Common hooks:\n",
    "- **Flake8:** It is a code linter to check our code for Line length and unused imports\n",
    "- **Black:** It is a code formatter that automatically reformats our code\n",
    "\n",
    "Other hooks:  https://pre-commit.com/hooks.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13099943",
   "metadata": {},
   "source": [
    "When we change configuration for pre-commit, we need to clean the cache:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193c2c68",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pre-commit clean && pre-commit install"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e176f38",
   "metadata": {},
   "source": [
    "To update hooks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70544f40",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pre-commit autoupdate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_notes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
