{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cc4fdcc",
   "metadata": {},
   "source": [
    "# Model Interpretability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc88f6c8",
   "metadata": {},
   "source": [
    "## Importance of Interpretability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72422491",
   "metadata": {},
   "source": [
    "## Taxonomy of Interpretation Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1e53b2",
   "metadata": {},
   "source": [
    "### Classifications:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed09ec86",
   "metadata": {},
   "source": [
    "### Python Libraries:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b50169",
   "metadata": {},
   "source": [
    "## Global Model Agnostic Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d65cde8",
   "metadata": {},
   "source": [
    "Global methods describe the average behavior of a machine learning model. They are often expressed as expected values based on the distribution of the data. We will cover:\n",
    "- **Partial dependence plots:** Illustrates the average feature effect marginalizing over other features.\n",
    "- **Cumulated local effect plots (ALE):** Corrects feature effect for feature dependence.\n",
    "- **Feature interaction (H2-statistic):** Quantifies to what extent the prediction is driven by joint effects of features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d6175b",
   "metadata": {},
   "source": [
    "### Partial Dependence Plots\n",
    "- Partial dependence plots were introduced by Friedman (1999) in the context of GBMs. \n",
    "- They show the marginal effect of one (univariate PDP) or two (bivariate PDP) features on the prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b09102",
   "metadata": {},
   "source": [
    "Advantage: simple, easy to explain to stakeholders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acae43bf",
   "metadata": {},
   "source": [
    "H2 statistics usage: estimate a GBM with all features, compute H2 for all feature interaction, find the strongest feature interaction, include in a parametric model (e.g. GLM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcdcb38",
   "metadata": {},
   "source": [
    "## Local model-agnostic methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a984f465",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
